Computer Science 499/599 at Northern Arizona University, Fall 2021

Topic: Unsupervised Learning

Dates: Aug 23 - Dec 10.

Meeting time/place: 
- CS499, MWF 8-8:50AM, Engineering building, room 314.
- CS599, TuTh 8-9:15AM, Health Professions building, room 229.

Syllabus: [[https://docs.google.com/document/d/1yhLOga-9vuuNin_LK3z7TO3h-i5QxFoWqYte5A9KyZI/edit?usp=sharing][Google Doc]].

Class Discord Link (will expire on 10/4/2021): https://discord.gg/WrM7QAxv 
 
** Reading links

*** For quizzes 

These provide background/theory about the algorithms we study in this class.
   
MLAPP by Murphy
- Author's web page https://www.cs.ubc.ca/~murphyk/MLbook/
- [[https://arizona-nau.userservices.exlibrisgroup.com/view/action/uresolver.do;jsessionid=44D57625A91B64FED37B94B305F9F939.app03.na03.prod.alma.dc04.hosted.exlibrisgroup.com:1801?operation=resolveService&package_service_id=20483326390003842&institutionId=3842&customerId=3840][full
  book online describing many machine learning algorithms from a
  computer science perspective]].

ESL by Hastie, Tibshirani, Friedman
- Free PDF available from author's web page
  https://web.stanford.edu/~hastie/ElemStatLearn/ describes many
  machine learning algorithms from a statistics perspective.

About computational complexity,
- The [[https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-4.html#%25_toc_%25_sec_1.2.3][SICP]] book, 1.2.3 "Orders of Growth," has a brief description in
  general terms (not specific to machine learning).
- The [[https://arizona-nau.primo.exlibrisgroup.com/discovery/fulldisplay?vid=01NAU_INST:01NAU&search_scope=MyInst_and_CI&tab=Everything&docid=alma991007591689703842&lang=en&context=L&adaptor=Local%2520Search%2520Engine&query=any,contains,algorithms%2520introduction&offset=0&virtualBrowse=true][CLRS]] book has a more detailed description in Chapter 3, "Growth
  of Functions" (not specific to machine learning).
- Wikipedia usually has a good/accurate characterization of the
  machine learning algorithms we study. For example [[https://en.wikipedia.org/wiki/K-means_clustering#Complexity][K-means
  clustering, section Complexity]].

*** For homeworks

These provide practical advice about how to write the R code necessary
for the homeworks.

Getting Started in R: Tinyverse Edition by Saghir Bashir and Dirk
Eddelbuettel.
- [[https://eddelbuettel.github.io/gsir-te/Getting-Started-in-R.pdf][PDF]].
- [[https://github.com/eddelbuettel/gsir-te][source code]].

Impatient R by Burns
- [[https://www.burns-stat.com/documents/tutorials/impatient-r/][web pages with practical R tutorials]].

fasteR: Becoming productive in R, as fast as possible, by Norm Matloff
- [[https://github.com/matloff/fasteR][github repo]].

Introductions to data.table (efficient R package for data manipulation).
- [[https://atrebas.github.io/post/2020-06-17-datatable-introduction/][A gentle introduction to data.table by Atrebas]].
- Official [[https://cloud.r-project.org/web/packages/data.table/vignettes/datatable-intro.html][datatable-intro vignette]].
- [[https://raw.githubusercontent.com/rstudio/cheatsheets/master/datatable.pdf][RStudio data.table cheat sheet]].

Tao Te Programming by Burns
- [[https://github.com/tdhock/cs499-599-fall-2020/blob/master/Burns.org][selected chapters]] from the book about how to become a good programmmer.
- [[https://www.burns-stat.com/documents/books/tao-te-programming/][web page with details about how to purchase the full book]].

Data visualization with ggplot2
- [[https://rcdata.nau.edu/genomic-ml/animint2-manual/Ch02-ggplot2.html][Grammar of graphics chapter of my Animint2 Manual]] (animint2 code is
  almost identical to ggplot2 code),
- [[https://www.youtube.com/watch?v=h29g21z0a68][Thomas Lin Pedersen's 150 minute webinar "Plotting Anything With
  ggplot2"]],
- [[https://uc-r.github.io/ggplot_intro][One web page UC ggplot intro]],
- [[https://r4ds.had.co.nz/data-visualisation.html][Data visualization chapter of R for Data Science]].

For CS599 grad students: guides to writing an R package with C/C++
code.
- [[https://teuder.github.io/rcpp4everyone_en/][Rcpp for Everyone by Masaki E. Tsuda]].
- [[https://webhome.phy.duke.edu/~rgb/General/c_book/c_book/][The C book by Mike Banahan, Declan Brady and Mark Doran]].
- [[https://github.com/tdhock/when-c][When and how to write low-level (C/C++) instead of high-level (R/Python) code?]]
- [[https://www.youtube.com/playlist?list=PLwc48KSH3D1OkObQ22NHbFwEzof2CguJJ][Make an R package with C++ code]], my tutorial screencast videos.
- [[https://r-pkgs.org/][R packages]] book by Wickham.

** Weekly schedule of Homeworks and reading

To do the homeworks you need to install [[https://cloud.r-project.org/][the most recent version of R]]
(4.1.1) with either the [[https://rstudio.com/products/rstudio/download/][RStudio]] IDE (for beginners) or the [[http://ess.r-project.org/][ESS]] IDE
(for students who already know/use emacs, or who want to learn, [[https://www.youtube.com/playlist?list=PLwc48KSH3D1Onsed66FPLywMSIQmAhUYJ][my
emacs tutorials]]).

[[https://drive.google.com/drive/folders/1PeTZJ29HRTM6BrsHTSHAdDfwZit8yA-P?usp=sharing][Folder of all class recordings and code demos from last year]]. [[file:demos/][Folder
with all code demos from this year]]. Yes you can copy and modify these
code demos for your homework, since they are a part of the class
material. But in general, copying code for your homework, from
classmates or internet sources, is strictly forbidden and will be
pursued as an academic integrity violation.

Your content and responses to each homework question will be graded as
follows
- Full credit for figures which show correct results, along with code
  which seems correct and is of high quality.
- [[https://docs.google.com/document/d/1W6-HdQLgHayOFXaQtscO5J5yf05G7E6KeXyiBJFcT7A/edit?usp=sharing][This General Usage Rubric]] will be used to grade the code
  quality/style/efficiency in each of your homeworks, -5 for each
  violation of these good coding rules.
- Some code and result figures, but clearly incorrect, -5 to -10.
- Missing code or figure, -10 to -20.
- Missing code and figure, -20 to -40.

Homework topics and readings for each week are listed below. The date
of the Monday of each week is written. Each homework is due Friday of
that week, 11:59PM.

- Aug 23, [[file:homeworks/1.org][Homework 1]]: installing R, reading CSV, data visualization using ggplot2.
  - [[file:2021-08-23-applications/slides.pdf][My slides on applications of ML]], [[https://www.youtube.com/watch?v=SRdzg-gzKXs&list=PLwc48KSH3D1M78ilQi35KPe2GHa7B_Rme&index=2&t=0s][My 20 minute intro to R video]],
    for more introductions to R and data visualization, see links
    under "For homeworks" above.
  - Quizzes Due Tues Aug 24: R Basics 1, R ggplot 1. Due Thurs Aug 26:
    R ggplot 2, R ggplot 3.
- Aug 30, [[file:homeworks/2-kmeans.org][Homework 2]]: K-means.
  - [[file:slides/02-clustering.pdf][Slides]], Introduction to clustering, MLAPP 25.1. Clustering evaluation,
    MLAPP-25.1.2. K-means is discussed in ESL-14.3.6, MLAPP-11.4.2.5.
  - Quiz due Sun Aug 29: Clustering 1. due Tues Aug 31: Kmeans 1.
- Sept 6, Labor day 9/6. [[file:homeworks/03-gaussian-mixture-models.org][Homework 3]]. Gaussian mixture models
  - [[file:slides/03-gaussian-mixtures.pdf][Slides]], ESL-14.3.7, MLAPP-11.4.2. [[file:mclust-models.jpg][mclust model names figure]].
  - Quiz due Tues Sept 7: mixture 1.
- Sept 13, [[file:homeworks/04-hierarchical-clustering.org][Homework 4]]: Hierarchical Clustering
  - [[file:slides/04-hierarhical-clustering.pdf][Slides]], ESL-14.3.12, MLAPP-25.5.1.
  - Quizzes Hierarhical 1-3.
- Sept 20, [[file:homeworks/05-clustering-model-selection.org][Homework 5]]: Clustering model selection
  - [[file:slides/05-clustering-model-selection.pdf][Slides]], Estimating the number of clusters, ESL-14.3.11. Model
    selection for latent variable models, MLAPP-11.5.
  - Quizzes model selection 1-3.
- Sept 27, [[file:exams/01-practice.org][Review]] and exam, [[file:homeworks/Rpkg.org][CS599 grad student R package coding
  project 1 due]], CS499 no week 6 homework.
- Oct 4, [[file:homeworks/07-binary-segmentation.org][Homework week 7]]: Binary segmentation
  - [[file:slides/07-binary-segmentation.pdf][Slides]], Intro to changepoint detection [[https://arxiv.org/pdf/1801.00718.pdf][Truong et al]]. sections
    1-2. Binary segmentation. Section 5.2.2. Estimating the number of
    changes. section 6.
  - Quizzes changepoint 1, binary segmentation 1.
- Oct 11, [[file:homeworks/08-dynamic-programming.org][Homework week 8]]: Optimal segmentation via dynamic programming.
  - [[file:slides/08-optimal-segmentation.pdf][Slides]], [[https://arxiv.org/pdf/1801.00718.pdf][Truong et al]] sections 4.1.1 (Models and Cost functions,
    Parametric Models, Maximum likelihood estimation), 5.1. (Optimal
    detection).
  - Quizzes changepoint 2, optimal segmentation 1-2.
- Oct 18, [[file:homeworks/09-hidden-markov-models.org][Homework week 9]]: Hidden Markov Models
  - [[file:slides/09-hidden-markov-models.pdf][Slides]], [[https://cloud.r-project.org/web/packages/depmixS4/vignettes/depmixS4.pdf][depmixS4 vignette]] section 2. Markov Models, MLAPP-17.2. Hidden
    Markov Models, MLAPP-17.3-5. Learning for HMMs, MLAPP-17.5.
  - Quizzes HMM 1-3.
- Oct 25, [[file:homeworks/10-segmentation-model-selection.org][Homework week 10]]: Segmentation model selection
  - [[file:slides/10-segmentation-model-selection.pdf][Slides]], for AIC/BIC read MLAPP-5.3.2.4 (BIC approximation to log
    marginal likelihood) and ESL-7.5 (Estimates of
    In-Sample Prediction Error) and ESL-7.7 (The Bayesian Approach and
    BIC). [[http://ml.nau.edu/viz/2021-10-21-curveAlignment/][Changepoint ROC curve interactive data viz 1]], [[http://ml.nau.edu/viz/2021-10-21-neuroblastomaProcessed-complex/][data viz 2]]
  - Quizzes HMM 4-5, model selection 4.
- Nov 1, [[file:exams/02-practice.org][Review and exam]]. [[file:homeworks/Rpkg.org][CS599 grad student R
  package coding project 2 due]], CS499 no homework week 11.
- Nov 8, Veterans day 11/11. [[file:homeworks/12-principal-components.org][Homework week 12]]: Principal Components Analysis
  - [[file:slides/12-principal-components.Rmd][Slides]], Principal Components Analysis, ESL-14.5. MLAPP-12.2.
  - Quizzes PCA 1-3.
- Nov 15, [[file:homeworks/13-auto-encoders.org][Homework week 13]]: Auto-encoders
  - [[file:slides/13-auto-encoders.pdf][Slides]], [[file:homeworks/13-auto-encoders-torch.R][torch+luz coding demo]], Deep generative models, MLAPP-28.2
    to 28.3. Deep auto-encoders, MLAPP-28.3.2. MLAPP-28.4.2 to 28.4.3.
  - Quizzes Autoencoders 1-3.
- Nov 22, Thanksgiving 11/25-26. [[file:homeworks/14-other-dimensionality-reduction.org][Homework week 14]]. 
  - [[file:slides/14-other-dimensionality-reduction.pdf][Slides]], Reading: [[https://cloud.r-project.org/web/packages/dimRed/vignettes/dimensionality-reduction.pdf][dimRed vignette]], no quiz.
- Nov 29, Reading week, [[file:exams/03-practice.org][final exam review questions]],
  [[file:homeworks/Rpkg.org][CS599 grad student extra credit R package
  coding project 3 due (this project is not required; you only have to
  do this if you want extra credit points)]].
- Final exams. CS499 Mon Dec 6, 7:30-9:30. CS599 Thurs Dec 9, 7:30-9:30.

** General Questions and Answers (FAQ)

- can I do my homework with an older version of R? Maybe, try it if
  you want, but homeworks will typically require using R packages,
  which are only tested with the most recent versions of R, so if you
  are getting errors with an old version of R, try upgrading to the
  most recent version.
- Some function give me a NULL result, how can I work around that? Try
  if(!is.null(result)){save your results}
- Some for loop over N items takes a long time, but failed/errored at
  the N-1'th iteration. How can I re-start computations where I left
  off? Try if(!some_key %in% names(result_list)){do the computations
  and save result with name some_key in result_list}

** How to ace this class

Before class you should prepare by doing the suggested
readings/videos. When you do that, write a summary in your own words
of every section. Also write questions that you have during your
reading so you can ask in class or office hours.

During class, take notes by writing what you understood in your own
words. Also I would suggest to ask questions in class as soon as you
need clarification.

After class, you should review your notes with one of your classmates
(ask one of the students who seem to be correctly answering a lot of
questions). Ask each other questions and try to teach/summarize some
of the material with each other -- that is one of the best ways to
learn.

Finally after doing all of the above, please come to office hours (see
syllabus), or email me to schedule a meeting.

